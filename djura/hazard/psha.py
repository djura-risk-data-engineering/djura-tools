from pathlib import Path
from typing import List
from scipy.interpolate import interp1d
from pandas import read_csv, DataFrame
import numpy as np
import json


def proc_oq_hazard_curve(
    poes: list[float],
    path_hazard_results: str | Path,
    out_file: str | Path = None,
    haz_file_start: str = 'hazard_curve-mean'
) -> None:
    """
    Process OpenQuake hazard curve results and store them in a JSON file.

    This function processes the hazard curve files generated by OpenQuake
    after performing Probabilistic Seismic Hazard Analysis (PSHA). For each
    hazard curve file, it interpolates the intensity measure levels (IMLs)
    corresponding to specified probabilities of exceedance (poes). The
    processed data, including the site location, investigation time, hazard
    curves, and interpolated IMLs, is then saved into a JSON file.

    Parameters
    ----------
    poes : list[float]
        List of probabilities of exceedance in a given investigation time
        (`investigation_time`) for which corresponding intensity measure
        levels (IMLs) will be obtained via interpolation.
    path_hazard_results : str | Path
        Path to the directory containing the OpenQuake hazard curve results.
    json_file : str | Path, optional
        Path and name of the output JSON file where the processed data will
        be saved. By default, it is saved as 'hazard.json'.
    haz_file_start : str, optional
        Prefix for the hazard curve files to process. Only files that start
        with this prefix will be processed. By default, this is set to
        'hazard_curve-mean'.

    Returns
    -------
    None

    Notes
    -----
    The output JSON file will contain the following keys:

    - `investigation_time`: The investigation time used in the PSHA
    (extracted from the hazard files).
    - `lat`: List of latitudes of the investigated sites.
    - `lon`: List of longitudes of the investigated sites.
    - `im`: List of intensity measure types (IMs) extracted from the hazard
    curve file names.
    - `cond_poes`: The provided list of probabilities of exceedance for which
    IMLs are calculated.
    - `cond_imls`: A dictionary containing interpolated IMLs corresponding to
    each IM for the given poes.
    - `hazard_curves`: A dictionary containing hazard curve data for each IM,
    including the original probabilities of exceedance and IMLs.

    Example
    -------
    >>> proc_oq_hazard_curve([0.1, 0.5], 'path/to/results', 'outputs.json')
    """

    # Convert paths to Path objects
    path_hazard_results = Path(path_hazard_results)

    # Initialise dictionary to store all outputs
    output_data = {
        "investigation_time": None,  # Will be set when reading files
        "lat": [],
        "lon": [],
        "im": [],
        "cond_poes": poes,
        "cond_imls": {},
        "hazard_curves": {}
    }

    # Read through each file in the outputs folder
    for file in path_hazard_results.iterdir():
        if file.name.startswith(haz_file_start):

            # Strip the IM out of the file name
            im_type = (file.stem.split('-')[2]).split('_')[0]

            # Load the results in as a dataframe
            df = read_csv(file, skiprows=1)

            # Get the column headers
            iml = list(df.columns.values)[3:]  # List of headers
            iml = [float(i[4:]) for i in iml]  # Strip out the actual IM values

            with file.open("r") as f:
                temp1 = f.readline().split(',')
                temp2 = list(filter(None, temp1))
                inv_t = float(list(filter(
                    lambda x: 'investigation_time=' in x, temp2
                ))[0].replace(" investigation_time=", ""))

                # Save inv_t once (assuming it is consistent across files)
                output_data["investigation_time"] = inv_t

            # For each of the sites investigated
            for site in np.arange(len(df)):

                # Append each site's info to the output dictionary
                output_data["lat"].append([df.lat[site]][0])
                output_data["lon"].append([df.lon[site]][0])
                output_data["im"].append(im_type)

                # Get the array of poe in inv_t and corresponding imls
                tmp1 = np.array(df.iloc[site, 3:].values)
                tmp2 = np.array(iml)
                # get rid of any infinite or nan value
                infs = np.isinf(tmp1)
                tmp1 = tmp1[~infs]
                tmp2 = tmp2[~infs]
                nans = np.isnan(tmp1)
                tmp1 = tmp1[~nans]
                tmp2 = tmp2[~nans]

                # Save hazard curve data in the dictionary
                output_data["hazard_curves"][f"{im_type}"] = {
                    "poe": tmp1.tolist(),
                    "iml": tmp2.tolist(),
                }

    # Get intensity measure levels corresponding to poes and store in
    # dictionary
    for idx, im in enumerate(output_data["hazard_curves"]):
        poe = output_data["hazard_curves"][im]["poe"]
        iml = output_data["hazard_curves"][im]["iml"]
        iml_interp = interp1d(poe, iml, kind='linear')(poes)
        output_data["cond_imls"][output_data["im"][idx]] = iml_interp.tolist()

    # Save the output dictionary as a JSON file
    if out_file is not None:
        out_file = Path(out_file)

        with open(out_file, 'w') as file:
            json.dump(output_data, file, indent=4)

    return output_data


def proc_oq_disaggregation_exc(
    path_disagg_results: str | Path,
    out_file: str | Path = None,
    disagg_file_start: str = 'Mag_Dist'
) -> dict:
    """
    Process disaggregation results from OpenQuake and store them in a JSON
    file.

    This function reads disaggregation data from OpenQuake results, including
    magnitudes (M) and distances (R) for different probabilities of exceedance
    (poes) and intensity measure types (IMTs). It calculates key metrics such
    as mean and modal magnitudes and distances, and stores the processed data
    in a JSON file for easy access and further analysis.

    Parameters
    ----------
    path_disagg_results : str | Path
        The directory containing the disaggregation result files produced by
        OpenQuake.
    json_file : str | Path, optional
        The output JSON file where the processed disaggregation data will be
        stored.
        Default is 'disaggregation.json'.
    disagg_file_start : str, optional
        Prefix of the disaggregation files to process. Files that begin with
        this prefix and do not contain 'Mag_Dist_Eps' will be processed.
        Default is 'Mag_Dist'.

    Returns
    -------
    dict
        A dictionary containing processed disaggregation data.

    Notes
    -----
    The function processes each disaggregation result file to extract the
    following:

    - `location`: Latitude and longitude of the site.
    - `investigation_time`: The investigation time used in the disaggregation.
    - `imt_disagg`: A dictionary where each intensity measure type (IMT)
    contains:
        - `poes`: List of probabilities of exceedance (poes) used in the
        disaggregation.
        - `return_periods`: Corresponding return periods for each poe.
        - `mean_mags`: List of mean magnitudes for each poe.
        - `mean_dists`: List of mean distances for each poe.
        - `mod_mags`: List of modal magnitudes (magnitude with the highest
        hazard contribution).
        - `mod_dists`: List of modal distances (distance with the highest
        hazard contribution).
        - `mag_dist_hazard_contributions`: A dictionary of hazard
        contributions for each poe,
          containing magnitudes, distances, and their respective hazard
          contributions.

    Example
    -------
    >>> proc_oq_disaggregation('results/disagg', 'disagg_output.json')
    """

    # Convert paths to Path objects
    path_disagg_results = Path(path_disagg_results)

    # Initialize dictionary to store results
    disagg = {
        "location": {"lat": None, "lon": None},
        "investigation_time": None,
        "imt_disagg": {}
    }

    for file in path_disagg_results.iterdir():
        if file.name.startswith(disagg_file_start) and \
           'eps' not in file.name.lower():
            # Load the dataframe
            df = read_csv(file, skiprows=1)

            # Extract hazard key (column starting with 'rlz' or 'mean')
            hz_key = next(key for key in df.keys()
                          if key.startswith('rlz') or key == 'mean')

            # Extract unique values for poes and imt
            poes = np.unique(df['poe']).tolist()
            poes.sort(reverse=True)
            ims = np.unique(df['imt'])

            # Extract salient information from the first line of the file
            with file.open("r") as f:
                first_line = f.readline().split(',')
                lon = float(next(filter(lambda x: 'lon=' in x, first_line)
                                 ).replace(" lon=", ""))
                lat = float(next(filter(lambda x: 'lat=' in x, first_line)
                                 ).replace(" lat=", "").replace("\"\n", ""))
                inv_t = float(next(filter(
                    lambda x: 'investigation_time=' in x, first_line
                )).replace(" investigation_time=", ""))

                # Set lat, lon, and investigation time in the dictionary (once)
                disagg["location"]["lat"] = lat
                disagg["location"]["lon"] = lon
                disagg["investigation_time"] = inv_t

            # Loop through each intensity measure (imt)
            for imt in ims:
                disagg["imt_disagg"][imt] = {
                    "poes": poes,
                    "return_periods": [],
                    "mean_mags": [],
                    "mean_dists": [],
                    "mod_mags": [],
                    "mod_dists": [],
                    "mag_dist_hazard_contributions": {},
                }

                # Loop through each probability of exceedance (poe)
                for poe in poes:
                    return_period = round(-inv_t / np.log(1 - poe))
                    disagg["imt_disagg"][imt]["return_periods"].append(
                        return_period)

                    # Filter data for current poe and imt
                    mag_data = df['mag'][(
                        df['poe'] == poe) & (df['imt'] == imt)]
                    dist_data = df['dist'][
                        (df['poe'] == poe) & (df['imt'] == imt)]
                    hz_cont_data = df[hz_key][
                        (df['poe'] == poe) & (df['imt'] == imt)]
                    # Normalize hazard contribution
                    hz_cont_data_norm = hz_cont_data / hz_cont_data.sum()

                    # Create a DataFrame to hold the magnitude, distance,
                    # and hazard contribution
                    data = DataFrame({
                        "mag": mag_data,
                        "dist": dist_data,
                        "hz_cont_exc": hz_cont_data_norm
                    })

                    # Compute modal (highest hazard contribution) values
                    mode = data.sort_values(by='hz_cont_exc', ascending=False
                                            ).iloc[0]
                    mode_mag = mode['mag']
                    mode_dist = mode['dist']

                    # Compute mean values
                    mean_mag = np.sum(data['mag'] * data['hz_cont_exc'])
                    mean_dist = np.sum(data['dist'] * data['hz_cont_exc'])

                    disagg["imt_disagg"][imt]["mean_mags"].append(
                        mean_mag)
                    disagg["imt_disagg"][imt]["mean_dists"].append(
                        mean_dist)
                    disagg["imt_disagg"][imt]["mod_mags"].append(
                        mode_mag)
                    disagg["imt_disagg"][imt]["mod_dists"].append(
                        mode_dist)

                    # Store magnitude, distance, and hazard contribution in
                    # the dictionary
                    disagg["imt_disagg"][imt][
                        "mag_dist_hazard_contributions"][f"poe_{poe}"] = {
                        "mag": mag_data.tolist(),
                        "dist": dist_data.tolist(),
                        "hz_cont_exc": hz_cont_data_norm.tolist(),
                        "gamma": hz_cont_data.tolist()
                    }

    if out_file is not None:
        out_file = Path(out_file)

        # Save the output dictionary as a JSON file
        with open(out_file, 'w') as file:
            json.dump(disagg, file, indent=4)

    return disagg


def proc_oq_disaggregation_occ(
    poes: List[float],
    path_disagg_results: str | Path,
    out_file: str | Path = None,
    disagg_file_start: str = 'Mag_Dist',
    tol: float = 0.05
) -> dict:
    """
    Process exceedance disaggregation results from OpenQuake, and computes
    occurrence disaggregation results store all of them in a JSON file.

    This function reads disaggregation data from OpenQuake results, including
    magnitudes (M) and distances (R) for different probabilities of exceedance
    (poes) and intensity measure types (IMTs). It calculates key metrics such
    as mean and modal magnitudes and distances, and stores the processed data
    in a JSON file for easy access and further analysis.

    The function internally calls the `proc_oq_disaggregation_exc` method to
    compute exceedance disaggregation. Additionally, it estimates occurrence
    disaggregation using the approximation proposed by Fox et al. (2016).
    Therefore, for each desired poe, the user must also compute disaggregation
    using the OpenQuake engine at 0.99poe.

    Parameters
    ----------
    poes : List[float]
        The list of poes at which occurrence disaggregation is computed.
    path_disagg_results : str | Path
        The directory containing the disaggregation result files produced by
        OpenQuake.
    json_file : str | Path, optional
        The output JSON file where the processed disaggregation data will be
        stored.
        Default is 'disaggregation.json'.
    disagg_file_start : str, optional
        Prefix of the disaggregation files to process. Files that begin with
        this prefix and do not contain 'Mag_Dist_Eps' will be processed.
        Default is 'Mag_Dist'.

    References
    ----------
    Fox MJ, Stafford PJ, Sullivan TJ. Seismic hazard disaggregation in
    performance-based earthquake engineering: occurrence or exceedance?
    Earthq Eng Struct Dyn 2016;45:835-42. https://doi.org/10.1002/eqe.2675.

    Returns
    -------
    dict
        A dictionary containing processed disaggregation data.

    Notes
    -----
    The function processes each disaggregation result file to extract the
    following:

    - `location`: Latitude and longitude of the site.
    - `investigation_time`: The investigation time used in the disaggregation.
    - `imt_disagg`: A dictionary where each intensity measure type (IMT)
    contains:
        - `poes`: List of probabilities of exceedance (poes) used in the
        disaggregation.
        - `return_periods`: Corresponding return periods for each poe.
        - `mean_mags`: List of mean magnitudes for each poe.
        - `mean_dists`: List of mean distances for each poe.
        - `mod_mags`: List of modal magnitudes (magnitude with the highest
        hazard contribution).
        - `mod_dists`: List of modal distances (distance with the highest
        hazard contribution).
        - `mag_dist_hazard_contributions`: A dictionary of hazard
        contributions for each poe, containing magnitudes, distances, and
        their respective hazard contributions in terms of exceedances
        and occurrences.

    Example
    -------
    To process disaggregation results stored in the directory 'results/disagg'
    and save them in 'disagg_output.json', you can run:

    >>> proc_oq_disaggregation_occ(
        [0.1, 0.01], 'results/disagg', 'disagg_output.json'
        )
    """

    disagg = proc_oq_disaggregation_exc(
        path_disagg_results, None, disagg_file_start
    )

    imts = list(disagg["imt_disagg"].keys())

    for imt in imts:
        data = disagg["imt_disagg"][imt]
        for target in poes:
            closest = [v for v in data["poes"] if v < target]
            if not closest:
                raise ValueError(
                    f"There is no smaller PoE than {target} "
                    "in disaggregation."
                )
            else:
                closest = max(closest)
                if (target - closest) / target > tol:
                    raise ValueError(
                        f"Add a close PoE to {target} to disaggregation PoEs"
                    )
            gamma_i = np.array(
                data["mag_dist_hazard_contributions"][f"poe_{target}"]["gamma"]
            )
            gamma_i_1 = np.array(
                data["mag_dist_hazard_contributions"][f"poe_{closest}"][
                    "gamma"
                ]
            )
            prob_im_m_r = (gamma_i_1 - gamma_i) / (
                np.sum(gamma_i_1) - np.sum(gamma_i)
            )
            # not required but let's make sure
            prob_im_m_r /= np.sum(prob_im_m_r)
            disagg["imt_disagg"][imt]["mag_dist_hazard_contributions"][
                f"poe_{target}"
            ]["hz_cont_occ"] = list(prob_im_m_r)

    if out_file is not None:
        out_file = Path(out_file)

        # Save the output dictionary as a JSON file
        with open(out_file, 'w') as file:
            json.dump(disagg, file, indent=4)

    return disagg


def proc_oq_disaggregation(
    path_disagg_results: str | Path,
    poes: List[float] = None,
    out_file: str | Path = None,
    disagg_file_start: str = "Mag_Dist",
    tol: float = 0.05,
) -> dict:
    """
    Wrapper function to process disaggregation results from OpenQuake and store
    them in a JSON file.

    This function selects between exceedance and occurrence disaggregation
    depending on whether a list of probabilities of exceedance (poes) is
    provided. It calculates key statistics such as mean and modal magnitudes
    and distances, and stores the results in a structured JSON file for
    downstream use.

    - If `poes` is provided, the function computes both exceedance and
      occurrence disaggregation (based on Fox et al. 2016).
    - If `poes` is not provided, it computes only exceedance disaggregation.

    It also removes magnitude-distance bins with zero hazard contributions
    to clean up the final data structure.

    Parameters
    ----------
    path_disagg_results : str | Path
        Path to the directory containing OpenQuake disaggregation output files.
    poes : List[float], optional
        List of probabilities of exceedance to compute occurrence
        disaggregation. If None, only exceedance disaggregation is processed.
        Must be None if hazard disaggregation was done using exceedance POEs
    out_file : str | Path, optional
        Path to the output JSON file where the processed results will be
        stored. If None, the results are not saved to file.
    disagg_file_start : str, optional
        Prefix used to identify relevant disaggregation result files.
        Files must start with this prefix and exclude 'Mag_Dist_Eps'.
        Default is 'Mag_Dist'.
    tol : float, optional
        Tolerance used to match provided poes with existing disaggregation poes
        when computing occurrence disaggregation. Default is 0.05.

    Returns
    -------
    dict
        A dictionary containing cleaned and processed disaggregation data,
        including mean/modal magnitudes and distances, return periods, and
        hazard contributions by magnitude-distance bins.

    Notes
    -----
    The returned dictionary structure includes:
    - `location`: Latitude and longitude of the site.
    - `investigation_time`: The investigation time from the OpenQuake analysis.
    - `imt_disagg`: Dictionary of results for each intensity measure type
    (IMT), containing:
        - `poes`, `return_periods`, `mean_mags`, `mean_dists`,
          `mod_mags`, `mod_dists`
        - `mag_dist_hazard_contributions`: Dictionary with disaggregated hazard
          data per PoE, including:
            - `mag`, `dist`: Bin edges
            - `hz_cont_exc`: Hazard contributions (exceedance)
            - `hz_cont_occ`: Hazard contributions (occurrence, if poes given)
            - `gamma`: Rate of exceedances for given mag and dist pair

    Example
    -------
    >>> proc_oq_disaggregation('results/disagg')
    >>> proc_oq_disaggregation('results/disagg', [0.1, 0.01], 'output.json')
    """

    if poes:
        disagg = proc_oq_disaggregation_occ(
            poes, path_disagg_results, out_file, disagg_file_start, tol
        )
    else:
        disagg = proc_oq_disaggregation_exc(
            path_disagg_results, out_file, disagg_file_start
        )

    imts = list(disagg["imt_disagg"].keys())
    for imt in imts:
        data = disagg["imt_disagg"][imt]["mag_dist_hazard_contributions"]
        poe_keys = list(data.keys())
        for poe in poe_keys:
            keys_to_filter = ["mag", "dist", "hz_cont_exc", "gamma"]
            if "hz_cont_occ" in data[poe]:
                valid_indices = [
                    i for i, hz in enumerate(data[poe]["hz_cont_occ"])
                    if hz != 0
                ]
                keys_to_filter.append("hz_cont_occ")
            else:
                valid_indices = [
                    i for i, hz in enumerate(data[poe]["hz_cont_exc"])
                    if hz != 0
                ]
            # Filter all relevant keys using valid indices
            for key in keys_to_filter:
                data[poe][key] = [data[poe][key][i] for i in valid_indices]

        disagg["imt_disagg"][imt]["mag_dist_hazard_contributions"] = data

    return disagg
